{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from data import data\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelBinarizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Column Names\n",
    "columns = ['age', 'workclass', 'fnlwgt','education','education-num', 'marital-status', \n",
    "           'occupation', 'relationship', 'race', 'sex', 'capital-gain','capital-loss',\n",
    "           'hours-per-week','native-country', 'income']\n",
    "\n",
    "adult = data('./adult.data', './adult.test', columns)\n",
    "\n",
    "# Drop Unkown\n",
    "adult.train_x = adult.train_x[(adult.train_x.values !='?').all(axis=1)]\n",
    "adult.test_x = adult.test_x[(adult.test_x.values !='?').all(axis=1)]\n",
    "\n",
    "# Remove Periods\n",
    "adult.train_x['income'] = adult.train_x['income'].str.replace(\"\\.\",\"\",regex=True)\n",
    "adult.test_x['income'] = adult.test_x['income'].str.replace(\"\\.\",\"\",regex=True)\n",
    "\n",
    "adult.train_y = adult.train_x['income']\n",
    "adult.test_y = adult.test_x['income']\n",
    "adult.train_x.drop('income', axis=1, inplace=True)\n",
    "adult.test_x.drop('income', axis=1, inplace=True)\n",
    "\n",
    "# Do the onehotencoding\n",
    "def transform_data(enc, data, column):\n",
    "    enc_df = pd.DataFrame(enc.transform(data[[column]]).toarray(),columns=enc.categories_[0])\n",
    "    for item in enc.categories_[0]:\n",
    "        data[item.strip()] = enc_df[item].to_numpy()\n",
    "    return data\n",
    "\n",
    "# Set up the one hot encoding\n",
    "def encode(df_train, df_test, column_name):\n",
    "    # Creates the one hot encoder\n",
    "    enc = OneHotEncoder()\n",
    "    enc.fit(df_train[[column_name]])\n",
    "    \n",
    "    df_train = transform_data(enc, df_train, column_name)\n",
    "    df_test = transform_data(enc, df_test, column_name)\n",
    "    \n",
    "    # Drops the old non-encoded data\n",
    "    df_train.drop(column_name,axis=1, inplace=True)\n",
    "    df_test.drop(column_name, axis=1, inplace=True)\n",
    "    \n",
    "    return df_train, df_test\n",
    "\n",
    "# Sets the classes that need to be encoded\n",
    "to_encode = ['workclass','education', 'marital-status', 'occupation',\n",
    "             'relationship', 'race', 'sex', 'native-country']\n",
    "\n",
    "# Encodes all the categories\n",
    "for category in to_encode:\n",
    "    adult.train_x, adult.test_x = encode(adult.train_x, adult.test_x, category)\n",
    "\n",
    "\n",
    "adult_con = copy.deepcopy(adult)\n",
    "\n",
    "\n",
    "continous = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss',\n",
    "             'hours-per-week']\n",
    "\n",
    "\n",
    "adult.train_x = adult.train_x.drop(continous, axis=1)\n",
    "adult.test_x = adult.test_x.drop(continous, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.86      0.89      0.88     11360\n",
      "        >50K       0.63      0.56      0.59      3700\n",
      "\n",
      "    accuracy                           0.81     15060\n",
      "   macro avg       0.75      0.73      0.73     15060\n",
      "weighted avg       0.80      0.81      0.81     15060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(adult.train_x,adult.train_y)\n",
    "predictions = clf.predict(adult.test_x)\n",
    "\n",
    "print(classification_report(adult.test_y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.95      0.42      0.58     11360\n",
      "        >50K       0.34      0.93      0.50      3700\n",
      "\n",
      "    accuracy                           0.54     15060\n",
      "   macro avg       0.65      0.67      0.54     15060\n",
      "weighted avg       0.80      0.54      0.56     15060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(adult.train_x, adult.train_y)\n",
    "predictions = nb.predict(adult.test_x)\n",
    "\n",
    "print(classification_report(adult.test_y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult = adult_con\n",
    "def average_binary(data):\n",
    "    avg = data.mean()\n",
    "    data = data.to_numpy()\n",
    "    for index, item in enumerate(data):\n",
    "        if item <= avg:\n",
    "            data[index] = 0.0\n",
    "        else:\n",
    "            data[index] = 1.0\n",
    "    return data\n",
    "\n",
    "to_binary = ['age', 'fnlwgt', 'education-num', \n",
    "             'capital-gain', 'capital-loss', \n",
    "             'hours-per-week']\n",
    "\n",
    "for category in to_binary:\n",
    "    adult.train_x[category] = average_binary(adult.train_x[category])\n",
    "    adult.test_x[category] = average_binary(adult.test_x[category])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.20363934e-01  4.21386220e-01  3.11694950e-01  5.37722347e-02\n",
      "   3.44510325e-02  1.69699448e-01  3.15886322e-02  8.42363525e-02\n",
      "   7.81230832e-01  1.28808015e-02  4.00736046e-02  4.94786342e-02\n",
      "   5.11142916e-04  2.55571458e-02  3.79268043e-02  1.24718871e-02\n",
      "   4.39582907e-03  7.05377223e-03  1.34941730e-02  1.21652014e-02\n",
      "   4.03802903e-02  4.65140053e-02  1.55591903e-01  8.28051523e-03\n",
      "   3.17521979e-01  5.20343488e-02  1.43120016e-03  8.89388673e-03\n",
      "   2.56287058e-01  2.58536087e-01  1.22674300e-03  1.51298303e-01\n",
      "   1.93212022e-02  4.40809650e-01  5.86792067e-02  7.01288080e-02\n",
      "   2.56798201e-01  3.03576608e-18  2.20813740e-02  1.16847270e-01\n",
      "   6.64485790e-03  1.67654876e-02  5.55101206e-02  1.79717849e-01\n",
      "   1.38008587e-02  1.52422817e-01  7.76937232e-03  1.27581272e-01\n",
      "   3.48599468e-02  9.20057248e-03  1.02228583e-04  3.64547127e-01\n",
      "   3.94602331e-02  2.00470251e-01  2.51789000e-01  1.43631159e-01\n",
      "   1.09384584e-02  3.00552034e-02  1.43017788e-01  8.89388673e-03\n",
      "   8.07094664e-01  1.00000000e+00  1.66533454e-15  2.04457166e-04\n",
      "   3.47577183e-03  1.84011450e-03  2.35125741e-03  3.88468616e-03\n",
      "   3.47577183e-03  9.20057248e-04  3.37354324e-03  3.06685749e-03\n",
      "   1.02228583e-03  5.52034349e-03  5.11142916e-04  2.04457166e-03\n",
      "   1.84011450e-03  1.02228583e-04  6.13371499e-04  5.11142916e-04\n",
      "   6.13371499e-04  1.12451441e-03  7.15600082e-04  7.15600082e-04\n",
      "   1.84011450e-03  4.29360049e-03  1.84011450e-03  7.15600082e-04\n",
      "   1.30852586e-02  1.22674300e-03  7.15600082e-04  1.43120016e-03\n",
      "   7.36045798e-03  1.73788591e-03  1.22674300e-03  4.90697199e-03\n",
      "   4.08914332e-04  2.55571458e-03  1.02228583e-03  1.02228583e-03\n",
      "   1.02228583e-03  9.13105704e-01  2.24902883e-03  3.06685749e-04]\n",
      " [ 6.09876543e-01  4.25248905e-01  3.74990044e-01  1.21306252e-01\n",
      "   6.52329749e-02  4.22700119e-01  3.36121067e-02  6.82596575e-02\n",
      "   6.75029869e-01  6.04540024e-02  1.22102748e-01  4.01433692e-02\n",
      "   3.98247710e-04  2.37355635e-02  2.34169654e-02  7.64635603e-03\n",
      "   5.25686977e-03  1.01951414e-02  2.36559140e-02  1.53723616e-02\n",
      "   2.93906810e-02  4.62763839e-02  1.85185185e-01  1.91158901e-02\n",
      "   3.24571884e-01  6.63480685e-02  1.03544405e-03  2.86738351e-02\n",
      "   1.90123457e-01  6.38378239e-16  7.16845878e-04  9.99283154e-01\n",
      "  -1.33573708e-16  2.22044605e-16 -2.60208521e-16  1.87350135e-16\n",
      "   4.81879729e-02  2.38948626e-04  1.98247710e-01  1.71724413e-01\n",
      "   4.43647949e-02  3.45679012e-02  6.96136997e-02  4.03823178e-02\n",
      "   7.96495420e-05  1.40023895e-01  2.96296296e-02  1.18598168e-01\n",
      "   2.77180406e-02  7.66228594e-02  9.92592593e-01  2.38948626e-04\n",
      "   5.49581840e-03  1.59299084e-03 -1.47104551e-15  7.96495420e-05\n",
      "   7.16845878e-03  2.94703305e-02  4.95420151e-02  6.13301474e-03\n",
      "   9.07686181e-01 -1.44328993e-15  1.00000000e+00  7.96495420e-04\n",
      "   3.74352847e-03  2.94703305e-03  1.27439267e-03  3.26563122e-03\n",
      "   1.03544405e-03  9.55794504e-04  2.30983672e-03  2.62843489e-03\n",
      "   8.76144962e-04  4.30107527e-03  1.43369176e-03  1.11509359e-03\n",
      "   7.16845878e-04  3.38813179e-20 -3.03576608e-18  7.16845878e-04\n",
      "   3.98247710e-04  4.93827160e-03  1.67264038e-03  6.37196336e-04\n",
      "   3.26563122e-03  1.67264038e-03  2.15053763e-03  5.57546794e-04\n",
      "   2.11071286e-02  8.76144962e-04  1.59299084e-04  6.37196336e-04\n",
      "   6.29231382e-03  1.99123855e-03  1.19474313e-03  2.46913580e-03\n",
      "   2.38948626e-04  2.30983672e-03  1.83193947e-03  3.18598168e-04\n",
      "   5.57546794e-04  9.14137794e-01  1.59299084e-03  8.76144962e-04]\n",
      " [ 2.79013292e-01  4.78527607e-01  2.74156442e-01  5.36809816e-02\n",
      "   3.46370143e-02  2.85020450e-01  2.70961145e-02  4.93353783e-02\n",
      "   7.88471370e-01  2.41564417e-02  7.33640082e-02  3.70654397e-02\n",
      "   5.11247444e-04  3.47648262e-02  4.89519427e-02  2.03220859e-02\n",
      "   5.36809816e-03  1.16308793e-02  1.63599182e-02  1.82770961e-02\n",
      "   3.11860941e-02  3.46370143e-02  1.52862986e-01  6.90184049e-03\n",
      "   3.39851738e-01  3.64263804e-02  2.30061350e-03  1.21421268e-02\n",
      "   2.28016360e-01  2.15362986e-01  3.68628739e-18  4.98466258e-03\n",
      "   2.31339468e-02  6.91845603e-01  4.66513292e-02  1.80214724e-02\n",
      "   7.70705521e-02  7.66871166e-04  1.69350716e-01  8.85736196e-02\n",
      "   4.69069530e-02  9.61145194e-02  7.01687117e-02  1.21037832e-01\n",
      "   8.94683027e-04  1.00843558e-01  2.50511247e-02  1.08256646e-01\n",
      "   2.85020450e-02  6.64621677e-02  2.05391260e-15  5.31186094e-01\n",
      "   5.54703476e-02  3.17612474e-01  9.57310838e-02 -3.19189120e-16\n",
      "   1.13752556e-02  2.95245399e-02  1.01738241e-01  8.56339468e-03\n",
      "   8.48798569e-01 -1.22124533e-15  1.00000000e+00  7.66871166e-04\n",
      "   3.32310838e-03  1.66155419e-03  2.17280164e-03  1.66155419e-03\n",
      "   2.55623722e-03  7.66871166e-04  4.85685072e-03  2.93967280e-03\n",
      "   7.66871166e-04  2.55623722e-03  7.66871166e-04  3.70654397e-03\n",
      "   1.91717791e-03 -1.08420217e-19  7.66871166e-04  6.39059305e-04\n",
      "   2.55623722e-04  3.45092025e-03  1.78936605e-03  1.15030675e-03\n",
      "   1.15030675e-03  2.17280164e-03  1.78936605e-03  3.83435583e-04\n",
      "   2.77351738e-02  1.27811861e-03  6.39059305e-04  1.02249489e-03\n",
      "   4.72903885e-03  1.78936605e-03  8.94683027e-04  3.83435583e-03\n",
      "   5.11247444e-04  2.17280164e-03  1.15030675e-03  3.83435583e-04\n",
      "   1.27811861e-04  9.06697342e-01  2.81186094e-03  2.55623722e-04]]\n",
      "[[ 6.50521921e-01  4.13778706e-01  1.00000000e+00  1.70981211e-01\n",
      "   8.76826722e-02  5.15240084e-01  4.36325678e-02  8.58037578e-02\n",
      "   6.13152401e-01  8.26722338e-02  1.12317328e-01  6.22129436e-02\n",
      "   2.08768267e-04  2.08166817e-17 -3.46944695e-17  1.90819582e-17\n",
      "   2.60208521e-17 -3.46944695e-18 -4.51028104e-17  4.33680869e-17\n",
      "   7.70354906e-02  1.21503132e-01  4.96868476e-01  5.13569937e-02\n",
      "   1.16573418e-15  1.77035491e-01 -4.33680869e-18  7.62004175e-02\n",
      "  -8.32667268e-16  1.06471816e-02  6.26304802e-04  9.82672234e-01\n",
      "   1.46137787e-03 -3.88578059e-16  2.29645094e-03  2.29645094e-03\n",
      "   4.59290188e-02  2.08768267e-04  8.26722338e-02  2.71189979e-01\n",
      "   2.25469729e-02  1.04384134e-02  1.79540710e-02  1.58663883e-02\n",
      "   2.08768267e-04  3.20459290e-01  2.52609603e-02  1.32776618e-01\n",
      "   3.77870564e-02  1.67014614e-02  9.76617954e-01  3.54906054e-03\n",
      "   4.38413361e-03  2.29645094e-03  1.29436326e-02  2.08768267e-04\n",
      "   2.29645094e-03  4.71816284e-02  3.15240084e-02  3.75782881e-03\n",
      "   9.15240084e-01  2.08768267e-04  9.99791232e-01  2.08768267e-04\n",
      "   5.63674322e-03  5.01043841e-03  1.25260960e-03  2.50521921e-03\n",
      "   2.08768267e-04  8.35073069e-04  1.87891441e-03  4.80167015e-03\n",
      "   2.29645094e-03  5.84551148e-03  1.87891441e-03  2.08768267e-04\n",
      "   4.17536534e-04 -4.06575815e-20  5.42101086e-20  1.46137787e-03\n",
      "   4.17536534e-04  1.14822547e-02  3.75782881e-03  6.26304802e-04\n",
      "   2.92275574e-03  1.46137787e-03  4.38413361e-03  4.17536534e-04\n",
      "   4.59290188e-03  6.26304802e-04 -2.00577402e-18  4.17536534e-04\n",
      "   9.81210856e-03  1.67014614e-03  6.26304802e-04  1.67014614e-03\n",
      "   2.08768267e-04  3.34029228e-03  3.96659708e-03  2.08768267e-04\n",
      "  -2.16840434e-19  9.09812109e-01  1.67014614e-03  1.46137787e-03]\n",
      " [ 2.69455632e-01  4.80966610e-01  2.66467455e-01  5.09289334e-02\n",
      "   3.44289983e-02  2.81278420e-01  2.61140704e-02  4.82005976e-02\n",
      "   7.93815772e-01  2.31258932e-02  7.22359361e-02  3.59880473e-02\n",
      "   5.19682993e-04  3.53384435e-02  4.97596466e-02  2.06573990e-02\n",
      "   5.45667143e-03  1.18227881e-02  1.66298558e-02  1.85786670e-02\n",
      "   3.11809796e-02  3.48187606e-02  1.47849812e-01  6.23619592e-03\n",
      "   3.41951410e-01  3.48187606e-02  2.33857347e-03  1.15629466e-02\n",
      "   2.30999091e-01  2.08522801e-01  3.36102673e-18  2.85825646e-03\n",
      "   2.26062102e-02  7.03261011e-01  4.59919449e-02  1.67597765e-02\n",
      "   7.61335585e-02  7.79524490e-04  1.71105626e-01  8.48382487e-02\n",
      "   4.74210731e-02  9.75704820e-02  7.11965701e-02  1.22775107e-01\n",
      "   9.09445238e-04  9.78303235e-02  2.53345459e-02  1.08613746e-01\n",
      "   2.85825646e-02  6.69091854e-02  1.99840144e-15  5.38131740e-01\n",
      "   5.59958425e-02  3.20514486e-01  8.53579317e-02 -3.26128013e-16\n",
      "   1.14330259e-02  2.93620891e-02  1.02247629e-01  8.57476939e-03\n",
      "   8.48382487e-01 -1.11022302e-15  1.00000000e+00  7.79524490e-04\n",
      "   3.37793946e-03  1.68896973e-03  2.20865272e-03  1.68896973e-03\n",
      "   2.59841497e-03  7.79524490e-04  4.80706769e-03  2.98817721e-03\n",
      "   5.19682993e-04  2.46849422e-03  7.79524490e-04  3.76770170e-03\n",
      "   1.94881123e-03 -1.01643954e-19  6.49603742e-04  6.49603742e-04\n",
      "   2.59841497e-04  3.37793946e-03  1.81889048e-03  1.16928674e-03\n",
      "   1.16928674e-03  2.20865272e-03  1.81889048e-03  3.89762245e-04\n",
      "   2.79329609e-02  1.29920748e-03  6.49603742e-04  1.03936599e-03\n",
      "   4.67714694e-03  1.68896973e-03  9.09445238e-04  3.89762245e-03\n",
      "   5.19682993e-04  2.20865272e-03  1.16928674e-03  3.89762245e-04\n",
      "   1.29920748e-04  9.06457061e-01  2.85825646e-03  2.59841497e-04]\n",
      " [ 5.87614446e-01  4.31078332e-01  1.83186799e-15  9.25737538e-02\n",
      "   5.12461851e-02  3.69277721e-01  2.79755849e-02  5.77314344e-02\n",
      "   7.10579858e-01  4.74313327e-02  1.28687691e-01  2.70854527e-02\n",
      "   5.08646999e-04  3.78942014e-02  3.73855544e-02  1.22075280e-02\n",
      "   8.39267548e-03  1.62767040e-02  3.77670397e-02  2.45422177e-02\n",
      "  -2.08166817e-16  2.35922393e-16  1.02695630e-15 -2.77555756e-17\n",
      "   5.20091556e-01 -1.11022302e-16  1.65310275e-03 -5.89805982e-17\n",
      "   3.03789420e-01  6.10622664e-16  7.62970498e-04  9.99237030e-01\n",
      "  -8.84708973e-17  1.99840144e-15 -5.55111512e-17  1.63064007e-16\n",
      "   4.93387589e-02  2.54323499e-04  2.67166836e-01  1.13301119e-01\n",
      "   5.73499491e-02  4.89572737e-02  1.00330621e-01  5.50610376e-02\n",
      "  -1.12757026e-17  3.25534079e-02  3.20447609e-02  1.09867752e-01\n",
      "   2.12360122e-02  1.12538149e-01  9.89954222e-01 -8.88178420e-16\n",
      "   6.61241099e-03  3.43336724e-03 -3.19189120e-16 -3.19189120e-16\n",
      "   1.00457782e-02  1.86927772e-02  6.02746694e-02  7.62970498e-03\n",
      "   9.03357070e-01  1.27161750e-04  9.99872838e-01  1.14445575e-03\n",
      "   2.54323499e-03  1.65310275e-03  1.27161750e-03  3.68769074e-03\n",
      "   1.52594100e-03  1.01729400e-03  2.67039674e-03  1.27161750e-03\n",
      "   2.54323499e-04  3.43336724e-03  1.14445575e-03  1.65310275e-03\n",
      "   8.90132248e-04 -1.01643954e-19  9.21571847e-19  2.54323499e-04\n",
      "   3.81485249e-04  1.01729400e-03  3.81485249e-04  6.35808749e-04\n",
      "   3.43336724e-03  1.78026450e-03  7.62970498e-04  6.35808749e-04\n",
      "   3.11546287e-02  1.01729400e-03  2.54323499e-04  7.62970498e-04\n",
      "   4.06917599e-03  2.28891150e-03  1.52594100e-03  2.92472024e-03\n",
      "   2.54323499e-04  1.65310275e-03  5.08646999e-04  3.81485249e-04\n",
      "   8.90132248e-04  9.16836216e-01  1.52594100e-03  5.08646999e-04]\n",
      " [ 6.50811008e-01  4.02770184e-01  2.94878804e-01  6.85256060e-02\n",
      "   3.93657736e-02  1.88627665e-01  3.73610352e-02  1.03699654e-01\n",
      "   7.34827775e-01  1.76781484e-02  5.44924367e-02  5.10297066e-02\n",
      "   9.11244760e-04  2.56971022e-02  2.80663386e-02  8.56570075e-03\n",
      "   5.28521961e-03  8.01895389e-03  1.91361400e-02  1.47621651e-02\n",
      "   4.46509933e-02  5.23054492e-02  1.22653545e-01  8.93019865e-03\n",
      "   3.67596136e-01  5.66794241e-02  7.28995808e-04  9.65919446e-03\n",
      "   2.27264443e-01  4.66192819e-01  2.00473847e-03  2.67723711e-01\n",
      "   2.64260980e-02  1.53089120e-02  9.80499362e-02  1.24293785e-01\n",
      "   2.59522508e-01  3.79470760e-19  2.69728449e-02  1.40149444e-01\n",
      "   8.01895389e-03  1.49444141e-02  6.23291416e-02  1.67486787e-01\n",
      "   1.43976672e-02  1.54547111e-01  7.10770913e-03  1.00236924e-01\n",
      "   3.33515582e-02  1.09349371e-02  9.43689571e-16  2.99435028e-01\n",
      "   3.31693093e-02  3.64497904e-02  3.74886094e-01  2.56059778e-01\n",
      "   1.36686714e-02  2.80663386e-02  1.41425187e-01  8.20120284e-03\n",
      "   8.08638600e-01  9.94532531e-01  5.46746856e-03  1.82248952e-04\n",
      "   4.19172590e-03  2.91598323e-03  2.73373428e-03  4.92072171e-03\n",
      "   3.46273009e-03  1.09349371e-03  2.91598323e-03  3.82722799e-03\n",
      "   1.09349371e-03  6.37871332e-03  7.28995808e-04  1.45799162e-03\n",
      "   2.36923638e-03 -6.77626358e-20  1.09349371e-03  5.46746856e-04\n",
      "   7.28995808e-04  1.09349371e-03  1.09349371e-03  7.28995808e-04\n",
      "   2.55148533e-03  3.28048114e-03  2.18698742e-03  7.28995808e-04\n",
      "   1.11171861e-02  9.11244760e-04  7.28995808e-04  1.45799162e-03\n",
      "   7.65445599e-03  1.64024057e-03  1.45799162e-03  6.56096227e-03\n",
      "   7.28995808e-04  3.46273009e-03  9.11244760e-04  1.09349371e-03\n",
      "   9.11244760e-04  9.07053034e-01  1.64024057e-03  3.64497904e-04]\n",
      " [ 1.31852880e-01  4.44367337e-01  3.33795975e-01  3.56234097e-02\n",
      "   2.84524636e-02  1.44575526e-01  2.49826509e-02  6.06060606e-02\n",
      "   8.37150127e-01  6.93962526e-03  2.17441591e-02  4.85773768e-02\n",
      "  -1.46367293e-18  2.52139718e-02  5.01966227e-02  1.73490632e-02\n",
      "   3.23849179e-03  5.78302105e-03  6.24566273e-03  8.79019200e-03\n",
      "   3.56234097e-02  3.93245431e-02  1.97085357e-01  7.40226694e-03\n",
      "   2.54684247e-01  4.62641684e-02  2.31320842e-03  8.09622947e-03\n",
      "   2.92389544e-01  4.99600361e-16  2.31320842e-04  2.08188758e-03\n",
      "   1.01781170e-02  9.78024520e-01  8.32755031e-03  1.15660421e-03\n",
      "   2.54915568e-01 -2.16840434e-19  1.57298173e-02  8.79019200e-02\n",
      "   4.85773768e-03  1.89683090e-02  4.64954892e-02  1.94078186e-01\n",
      "   1.29539672e-02  1.49433264e-01  8.55887115e-03  1.61461948e-01\n",
      "   3.72426556e-02  7.40226694e-03  0.00000000e+00  4.44829979e-01\n",
      "   4.69581309e-02  4.07356003e-01  1.00855887e-01  2.77555756e-17\n",
      "   7.63358779e-03  3.28475596e-02  1.45500810e-01  9.71547536e-03\n",
      "   8.04302568e-01  1.00000000e+00  1.22124533e-15  2.31320842e-04\n",
      "   2.54452926e-03  4.62641684e-04  1.85056674e-03  2.54452926e-03\n",
      "   3.46981263e-03  6.93962526e-04  3.93245431e-03  2.08188758e-03\n",
      "   9.25283368e-04  4.39509600e-03  2.31320842e-04  2.77585010e-03\n",
      "   1.15660421e-03  2.31320842e-04  2.31320842e-04  4.62641684e-04\n",
      "   4.62641684e-04  1.15660421e-03  2.31320842e-04  6.93962526e-04\n",
      "   9.25283368e-04  5.55170021e-03  1.38792505e-03  6.93962526e-04\n",
      "   1.54984964e-02  1.61924589e-03  6.93962526e-04  1.38792505e-03\n",
      "   7.17094610e-03  1.85056674e-03  9.25283368e-04  2.77585010e-03\n",
      "   6.50521303e-19  1.38792505e-03  1.15660421e-03  9.25283368e-04\n",
      "   1.15660421e-03  9.20888272e-01  3.00717095e-03  2.31320842e-04]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.40563530e-01 4.15736310e-01 9.92557150e-01 ... 9.14938862e-01\n",
      "  2.12652844e-03 5.31632111e-04]\n",
      " [5.15316542e-01 3.94145677e-01 3.92784207e-01 ... 8.78829135e-01\n",
      "  2.72294078e-03 6.80735194e-04]\n",
      " [7.88208907e-02 4.86062160e-01 1.43543736e-01 ... 8.98429990e-01\n",
      "  4.80615187e-03 3.20410125e-04]\n",
      " ...\n",
      " [9.11214953e-02 4.46261682e-01 2.97062750e-02 ... 9.19893191e-01\n",
      "  3.67156208e-03 3.33778371e-04]\n",
      " [7.16517857e-01 4.11830357e-01 1.01283482e-01 ... 9.14899554e-01\n",
      "  1.11607143e-03 2.79017857e-04]\n",
      " [3.73820755e-01 4.81132075e-01 3.67688679e-01 ... 9.13207547e-01\n",
      "  1.41509434e-03 2.35849057e-04]]\n"
     ]
    }
   ],
   "source": [
    "kmeans = []\n",
    "kmeans_y = []\n",
    "\n",
    "# Build the Kmeans \n",
    "kmeans.append(KMeans(n_clusters=3))\n",
    "kmeans.append(KMeans(n_clusters=5))\n",
    "kmeans.append(KMeans(n_clusters=10))\n",
    "\n",
    "for kmean in kmeans:\n",
    "    kmean.fit(adult.train_x)\n",
    "    print(kmean.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8\n",
      "Accuracy: 0.9\n",
      "Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "knn = []\n",
    "knn_y = []\n",
    "\n",
    "knn.append(KNeighborsClassifier(3))\n",
    "knn.append(KNeighborsClassifier(5))\n",
    "knn.append(KNeighborsClassifier(10))\n",
    "\n",
    "for clf in knn:\n",
    "    clf.fit(adult.train_x, adult.train_y.values.ravel())\n",
    "    pred = clf.predict(adult.test_x.tail(10))\n",
    "    print(\"Accuracy: {}\".format(accuracy_score(adult.test_y.tail(10), pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.87      0.93      0.90     11360\n",
      "        >50K       0.72      0.57      0.64      3700\n",
      "\n",
      "    accuracy                           0.84     15060\n",
      "   macro avg       0.79      0.75      0.77     15060\n",
      "weighted avg       0.83      0.84      0.83     15060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='poly')\n",
    "clf.fit(adult.train_x, adult.train_y)\n",
    "pred = clf.predict(adult.test_x)\n",
    "print(classification_report(adult.test_y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.001, hidden_layer_sizes=(5, 2), max_iter=500)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(alpha=1e-03, hidden_layer_sizes=(5,2), max_iter=500)\n",
    "clf.fit(adult.train_x, adult.train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.88      0.92      0.90     11360\n",
      "        >50K       0.71      0.60      0.65      3700\n",
      "\n",
      "    accuracy                           0.84     15060\n",
      "   macro avg       0.79      0.76      0.78     15060\n",
      "weighted avg       0.84      0.84      0.84     15060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(adult.test_x)\n",
    "print(classification_report(adult.test_y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
